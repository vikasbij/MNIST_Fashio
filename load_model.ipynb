{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import helper\n",
    "import fc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,),(0.5,))])\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 231,
       "width": 231
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0,:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fc_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9979f28f17db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mfc_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0.003\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fc_model' is not defined"
     ]
    }
   ],
   "source": [
    "model =  fc_model.Network(784,10,[512,256,128])\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr= 0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2..  Training Loss: 1.525..  Test Loss: 0.856..  Test Accuracy: 0.660\n",
      "Epoch: 1/2..  Training Loss: 0.958..  Test Loss: 0.762..  Test Accuracy: 0.714\n",
      "Epoch: 1/2..  Training Loss: 0.903..  Test Loss: 0.671..  Test Accuracy: 0.751\n",
      "Epoch: 1/2..  Training Loss: 0.868..  Test Loss: 0.661..  Test Accuracy: 0.732\n",
      "Epoch: 1/2..  Training Loss: 0.812..  Test Loss: 0.636..  Test Accuracy: 0.758\n",
      "Epoch: 1/2..  Training Loss: 0.730..  Test Loss: 0.637..  Test Accuracy: 0.759\n",
      "Epoch: 1/2..  Training Loss: 0.778..  Test Loss: 0.628..  Test Accuracy: 0.764\n",
      "Epoch: 1/2..  Training Loss: 0.775..  Test Loss: 0.587..  Test Accuracy: 0.797\n",
      "Epoch: 1/2..  Training Loss: 0.795..  Test Loss: 0.588..  Test Accuracy: 0.789\n",
      "Epoch: 1/2..  Training Loss: 0.745..  Test Loss: 0.587..  Test Accuracy: 0.782\n",
      "Epoch: 1/2..  Training Loss: 0.790..  Test Loss: 0.658..  Test Accuracy: 0.769\n",
      "Epoch: 1/2..  Training Loss: 0.781..  Test Loss: 0.583..  Test Accuracy: 0.778\n",
      "Epoch: 1/2..  Training Loss: 0.776..  Test Loss: 0.604..  Test Accuracy: 0.803\n",
      "Epoch: 1/2..  Training Loss: 0.729..  Test Loss: 0.583..  Test Accuracy: 0.792\n",
      "Epoch: 1/2..  Training Loss: 0.739..  Test Loss: 0.568..  Test Accuracy: 0.804\n",
      "Epoch: 1/2..  Training Loss: 0.735..  Test Loss: 0.588..  Test Accuracy: 0.798\n",
      "Epoch: 1/2..  Training Loss: 0.768..  Test Loss: 0.609..  Test Accuracy: 0.792\n",
      "Epoch: 1/2..  Training Loss: 0.748..  Test Loss: 0.548..  Test Accuracy: 0.807\n",
      "Epoch: 1/2..  Training Loss: 0.695..  Test Loss: 0.548..  Test Accuracy: 0.807\n",
      "Epoch: 1/2..  Training Loss: 0.743..  Test Loss: 0.560..  Test Accuracy: 0.802\n",
      "Epoch: 1/2..  Training Loss: 0.739..  Test Loss: 0.575..  Test Accuracy: 0.811\n",
      "Epoch: 1/2..  Training Loss: 0.724..  Test Loss: 0.572..  Test Accuracy: 0.803\n",
      "Epoch: 1/2..  Training Loss: 0.692..  Test Loss: 0.542..  Test Accuracy: 0.803\n",
      "Epoch: 2/2..  Training Loss: 0.712..  Test Loss: 0.544..  Test Accuracy: 0.814\n",
      "Epoch: 2/2..  Training Loss: 0.651..  Test Loss: 0.556..  Test Accuracy: 0.807\n",
      "Epoch: 2/2..  Training Loss: 0.703..  Test Loss: 0.544..  Test Accuracy: 0.808\n",
      "Epoch: 2/2..  Training Loss: 0.717..  Test Loss: 0.524..  Test Accuracy: 0.820\n",
      "Epoch: 2/2..  Training Loss: 0.687..  Test Loss: 0.570..  Test Accuracy: 0.802\n",
      "Epoch: 2/2..  Training Loss: 0.691..  Test Loss: 0.581..  Test Accuracy: 0.799\n",
      "Epoch: 2/2..  Training Loss: 0.737..  Test Loss: 0.551..  Test Accuracy: 0.810\n",
      "Epoch: 2/2..  Training Loss: 0.700..  Test Loss: 0.559..  Test Accuracy: 0.802\n",
      "Epoch: 2/2..  Training Loss: 0.667..  Test Loss: 0.513..  Test Accuracy: 0.816\n",
      "Epoch: 2/2..  Training Loss: 0.745..  Test Loss: 0.527..  Test Accuracy: 0.812\n",
      "Epoch: 2/2..  Training Loss: 0.683..  Test Loss: 0.540..  Test Accuracy: 0.818\n",
      "Epoch: 2/2..  Training Loss: 0.683..  Test Loss: 0.522..  Test Accuracy: 0.822\n",
      "Epoch: 2/2..  Training Loss: 0.667..  Test Loss: 0.522..  Test Accuracy: 0.820\n",
      "Epoch: 2/2..  Training Loss: 0.705..  Test Loss: 0.524..  Test Accuracy: 0.813\n",
      "Epoch: 2/2..  Training Loss: 0.659..  Test Loss: 0.536..  Test Accuracy: 0.817\n",
      "Epoch: 2/2..  Training Loss: 0.729..  Test Loss: 0.528..  Test Accuracy: 0.825\n",
      "Epoch: 2/2..  Training Loss: 0.682..  Test Loss: 0.540..  Test Accuracy: 0.818\n",
      "Epoch: 2/2..  Training Loss: 0.752..  Test Loss: 0.525..  Test Accuracy: 0.823\n",
      "Epoch: 2/2..  Training Loss: 0.722..  Test Loss: 0.527..  Test Accuracy: 0.816\n",
      "Epoch: 2/2..  Training Loss: 0.662..  Test Loss: 0.523..  Test Accuracy: 0.811\n",
      "Epoch: 2/2..  Training Loss: 0.643..  Test Loss: 0.562..  Test Accuracy: 0.814\n",
      "Epoch: 2/2..  Training Loss: 0.679..  Test Loss: 0.555..  Test Accuracy: 0.813\n",
      "Epoch: 2/2..  Training Loss: 0.702..  Test Loss: 0.520..  Test Accuracy: 0.823\n"
     ]
    }
   ],
   "source": [
    "fc_model.train(model, trainloader, testloader, criterion,optimizer,epochs =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is :  Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ") /n\n",
      "The state_dict keys : odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Model is : \", model, '/n')\n",
    "print('The state_dict keys :', model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('hidden_layers.0.weight', tensor([[ 0.0486,  0.0366,  0.0150,  ...,  0.0761,  0.0569,  0.0635],\n",
      "        [ 0.0502,  0.0583,  0.0938,  ...,  0.0431,  0.0997,  0.0684],\n",
      "        [ 0.0231,  0.0082,  0.0589,  ...,  0.0020,  0.0575,  0.0182],\n",
      "        ...,\n",
      "        [ 0.0859,  0.0479,  0.0313,  ...,  0.0345,  0.0836,  0.0841],\n",
      "        [ 0.0351,  0.0367, -0.0048,  ...,  0.0253, -0.0009,  0.0456],\n",
      "        [ 0.0643,  0.0464,  0.0539,  ...,  0.0880,  0.0601,  0.0651]])), ('hidden_layers.0.bias', tensor([-0.0691, -0.0765, -0.0157, -0.1014, -0.0281, -0.0447, -0.0314, -0.0532,\n",
      "        -0.1027, -0.0360, -0.0438, -0.0486, -0.0445, -0.1001, -0.0646, -0.0265,\n",
      "        -0.1292,  0.0014, -0.1164, -0.1299, -0.0382, -0.0651, -0.0657, -0.0146,\n",
      "         0.0381, -0.0411, -0.0128, -0.0751, -0.1420, -0.0802, -0.0951, -0.0225,\n",
      "        -0.0179, -0.0127, -0.0934, -0.0126, -0.0345, -0.0667, -0.0826, -0.0914,\n",
      "        -0.0136, -0.0245, -0.0279, -0.0680, -0.0785, -0.1277,  0.0038, -0.1141,\n",
      "        -0.0438, -0.1235, -0.0954,  0.0594, -0.1102, -0.0139, -0.1068, -0.1253,\n",
      "        -0.0939, -0.0614, -0.1218, -0.0243, -0.1798, -0.0229, -0.0536, -0.0214,\n",
      "        -0.0625, -0.0617, -0.0359, -0.0124, -0.0441, -0.0132, -0.0641, -0.1049,\n",
      "        -0.0624, -0.0277,  0.0058, -0.0166, -0.1360, -0.0624, -0.0414, -0.0206,\n",
      "        -0.1076,  0.0043, -0.0913, -0.0503, -0.0209, -0.0775, -0.0004, -0.1428,\n",
      "        -0.0580, -0.1808,  0.0006,  0.0081, -0.1010, -0.0370, -0.0138, -0.1125,\n",
      "        -0.0682, -0.0284, -0.1668, -0.0357, -0.0662, -0.0612, -0.1128, -0.1097,\n",
      "        -0.0766, -0.0093, -0.0424, -0.0980, -0.1371, -0.0468, -0.0754, -0.0194,\n",
      "        -0.0938, -0.0221, -0.1056, -0.0337,  0.0026, -0.1386, -0.0571, -0.0304,\n",
      "        -0.0313, -0.1178, -0.1280, -0.0621, -0.1128, -0.0395, -0.1051, -0.0385,\n",
      "        -0.0858, -0.0216, -0.0244, -0.0413, -0.1099,  0.0106, -0.0437, -0.0592,\n",
      "        -0.0430, -0.0706, -0.1719, -0.0906, -0.0899, -0.0533, -0.0517, -0.1007,\n",
      "         0.0288, -0.0734, -0.0586, -0.0909, -0.1137, -0.0911, -0.0506, -0.1054,\n",
      "        -0.1174, -0.1075, -0.0160,  0.0059, -0.0314,  0.0037,  0.0165, -0.1592,\n",
      "        -0.1710, -0.0137, -0.0450, -0.0526, -0.0183, -0.0697, -0.0338, -0.0662,\n",
      "        -0.0135, -0.0377,  0.0215, -0.0278, -0.0905, -0.0509, -0.0849, -0.0951,\n",
      "        -0.0278, -0.0224, -0.1760, -0.0575, -0.0445, -0.0873, -0.1393, -0.0955,\n",
      "        -0.0684, -0.1153, -0.0841, -0.0466, -0.0242, -0.1186, -0.0734, -0.1263,\n",
      "        -0.0739, -0.0634, -0.0917, -0.0515, -0.0967,  0.0217, -0.0254, -0.1007,\n",
      "        -0.0651, -0.1134, -0.0564, -0.0533, -0.0523, -0.0582, -0.1632,  0.0114,\n",
      "        -0.0440, -0.0835, -0.0031,  0.0321, -0.0559, -0.0859, -0.0680, -0.0334,\n",
      "        -0.0087, -0.1101, -0.0524, -0.0526, -0.0644, -0.0570, -0.0218, -0.0349,\n",
      "        -0.0970, -0.0643, -0.0375, -0.0824, -0.0159, -0.0102, -0.1052, -0.0894,\n",
      "        -0.0227, -0.0414, -0.0645, -0.0485, -0.0983, -0.1583, -0.1573, -0.1139,\n",
      "        -0.0376, -0.0975, -0.0450, -0.0393, -0.0592, -0.0641, -0.0830, -0.0621,\n",
      "        -0.0196, -0.0196, -0.0403, -0.1195, -0.0674, -0.0386, -0.1075, -0.0348,\n",
      "        -0.0757, -0.0781, -0.1444, -0.0104, -0.1098, -0.0901, -0.0676, -0.0675,\n",
      "        -0.0329, -0.0788,  0.0131, -0.1212, -0.0589, -0.1239, -0.0116, -0.0702,\n",
      "        -0.2529, -0.0100, -0.0325, -0.0794, -0.0297, -0.0913, -0.0982, -0.0591,\n",
      "        -0.1522, -0.0082, -0.0907,  0.0009, -0.0302, -0.0530, -0.0806, -0.0792,\n",
      "        -0.0491, -0.1038, -0.0479, -0.1106, -0.0060, -0.0647, -0.1100, -0.1195,\n",
      "        -0.0323, -0.0493, -0.1190, -0.0404, -0.0311, -0.0748, -0.0453, -0.0047,\n",
      "        -0.0681, -0.0186, -0.0387,  0.0072, -0.0516, -0.0461, -0.0285, -0.1100,\n",
      "        -0.0820, -0.1455, -0.0714, -0.0951, -0.0994, -0.0660, -0.1176, -0.0435,\n",
      "        -0.0478, -0.0534, -0.0207, -0.1231, -0.1197, -0.0995, -0.0805, -0.0417,\n",
      "        -0.1159, -0.0183, -0.0373, -0.0758, -0.0423, -0.0951, -0.0612, -0.0362,\n",
      "        -0.0721, -0.0781, -0.0036, -0.0830, -0.0119, -0.0779, -0.0697, -0.0496,\n",
      "        -0.0657, -0.0243, -0.0138, -0.0312, -0.1260, -0.0892, -0.1188,  0.0018,\n",
      "        -0.0124, -0.0371, -0.0387, -0.1394, -0.0385, -0.0305,  0.0209, -0.0346,\n",
      "        -0.1053, -0.1114, -0.0877, -0.1932, -0.0323, -0.1279, -0.0282, -0.0088,\n",
      "        -0.1006, -0.0482, -0.0982, -0.0260, -0.0912, -0.0534, -0.0512, -0.0767,\n",
      "        -0.1114, -0.0636, -0.0960, -0.0462, -0.1654, -0.1013, -0.1201, -0.0624,\n",
      "        -0.0651, -0.0499, -0.0720, -0.0479, -0.0340, -0.0473, -0.0404, -0.0145,\n",
      "        -0.1129, -0.1077, -0.0223, -0.1567, -0.0731, -0.0446, -0.1152, -0.0522,\n",
      "        -0.0729, -0.0560, -0.0659, -0.0849, -0.0672, -0.1054, -0.0682, -0.0771,\n",
      "        -0.0750, -0.0463, -0.0553, -0.0988, -0.0585, -0.0788, -0.0376, -0.0670,\n",
      "        -0.1762, -0.0682, -0.0768, -0.0290, -0.0280, -0.0252, -0.0612,  0.0075,\n",
      "        -0.0742, -0.0284, -0.0713, -0.0526, -0.1150, -0.1488, -0.0278, -0.0204,\n",
      "        -0.0459, -0.0175, -0.0480, -0.1171, -0.0246, -0.0952, -0.1207, -0.1475,\n",
      "        -0.1114, -0.0732, -0.0119, -0.0585, -0.0457, -0.1265, -0.0168, -0.0651,\n",
      "        -0.0043, -0.0162, -0.1269, -0.1079, -0.0577,  0.0075, -0.0524, -0.0827,\n",
      "        -0.0755, -0.0717, -0.0248, -0.0370, -0.0567, -0.0155, -0.0240, -0.1148,\n",
      "        -0.0534, -0.0551, -0.0346, -0.1151, -0.0152, -0.0237,  0.0043, -0.0798,\n",
      "        -0.0475, -0.0361, -0.1275, -0.0379,  0.0460, -0.0549, -0.0990, -0.1543,\n",
      "        -0.1167, -0.0382, -0.0714, -0.0136,  0.0070, -0.1923, -0.0558, -0.0592,\n",
      "        -0.1104, -0.1195, -0.0556, -0.0930, -0.0870, -0.1173, -0.0877, -0.1249,\n",
      "        -0.0521, -0.1556, -0.0313, -0.0734, -0.0665,  0.0089, -0.0847, -0.0757,\n",
      "        -0.0875, -0.0230, -0.0828, -0.1280, -0.0651, -0.0311, -0.0405, -0.0441])), ('hidden_layers.1.weight', tensor([[-0.0010, -0.0290, -0.0383,  ...,  0.1329, -0.0767,  0.0281],\n",
      "        [ 0.0428, -0.0599, -0.0328,  ..., -0.1188, -0.0602,  0.0137],\n",
      "        [-0.0247,  0.0157,  0.0163,  ..., -0.1179, -0.0081,  0.0017],\n",
      "        ...,\n",
      "        [-0.0327, -0.0200, -0.0149,  ...,  0.0354,  0.0156,  0.0041],\n",
      "        [-0.0384,  0.1155,  0.0062,  ..., -0.1051,  0.0096,  0.0206],\n",
      "        [-0.0063, -0.0099,  0.0034,  ...,  0.0599, -0.0159, -0.0365]])), ('hidden_layers.1.bias', tensor([-0.0121,  0.0171,  0.0742,  0.0095, -0.0524, -0.1292, -0.0414,  0.0496,\n",
      "         0.1557, -0.0280, -0.0429,  0.0430, -0.0485,  0.0349, -0.1900, -0.0278,\n",
      "         0.0592, -0.4477, -0.3158, -0.1489, -0.0101,  0.0365, -0.0026, -0.1040,\n",
      "        -0.0196,  0.0605,  0.0161, -0.0929, -0.1515,  0.1337,  0.1658, -0.2040,\n",
      "        -0.3469, -0.2091, -0.2034, -0.1768, -0.0074, -0.1229, -0.3284, -0.0944,\n",
      "         0.0803, -0.0511,  0.0065, -0.2109, -0.3059,  0.1194, -0.2224,  0.1425,\n",
      "         0.0453, -0.0077, -0.1734, -0.2293, -0.3258, -0.1222, -0.2709, -0.1751,\n",
      "        -0.1436, -0.2365, -0.3971,  0.0114,  0.0499, -0.0573, -0.3958,  0.0890,\n",
      "        -0.1683,  0.1372,  0.1749, -0.0924, -0.0962,  0.2319, -0.0143, -0.1914,\n",
      "        -0.0312, -0.2281, -0.2000, -0.2315, -0.0527, -0.1310,  0.0638, -0.0153,\n",
      "        -0.2360,  0.1397, -0.0518,  0.0434, -0.1887, -0.0930, -0.0257,  0.0830,\n",
      "         0.2175, -0.2084, -0.1624, -0.4173, -0.0077, -0.0208, -0.1150, -0.0255,\n",
      "        -0.1870, -0.1883, -0.2407,  0.1152,  0.2238, -0.1426, -0.0362,  0.2005,\n",
      "        -0.2727,  0.0130,  0.0628, -0.1964, -0.2099, -0.1515, -0.0681,  0.0497,\n",
      "        -0.1503, -0.2027, -0.1326,  0.0196, -0.0267,  0.1725, -0.1146,  0.1032,\n",
      "         0.0010, -0.2187, -0.1133,  0.1432, -0.1484, -0.2040, -0.2101,  0.2002,\n",
      "        -0.1724, -0.1495, -0.1878, -0.1400,  0.0012,  0.1204, -0.2547,  0.0139,\n",
      "         0.1784, -0.0563,  0.1539, -0.0275,  0.0889, -0.2435, -0.0817,  0.0670,\n",
      "        -0.1837, -0.0263,  0.0516,  0.0375,  0.1187,  0.0578,  0.0530, -0.0241,\n",
      "        -0.0690, -0.0606, -0.0201,  0.1149,  0.0553, -0.1426, -0.2510, -0.1170,\n",
      "         0.0893,  0.0163,  0.0232, -0.3212,  0.2200, -0.1173, -0.1549, -0.2390,\n",
      "         0.4311,  0.3645, -0.0729,  0.1536, -0.0171,  0.0008, -0.0092,  0.0236,\n",
      "        -0.2685, -0.0116, -0.0966,  0.0018, -0.0176, -0.0922,  0.0017, -0.1530,\n",
      "        -0.1344,  0.0495, -0.1684, -0.0915, -0.2844, -0.1787, -0.1045,  0.1441,\n",
      "        -0.1393, -0.1631, -0.0350,  0.1126, -0.1145, -0.0363, -0.2750, -0.0563,\n",
      "        -0.0295, -0.2569, -0.1355, -0.3069,  0.0775,  0.1843, -0.1893, -0.2442,\n",
      "        -0.0817,  0.1675, -0.2612, -0.0099,  0.1299, -0.1245, -0.0372, -0.1434,\n",
      "        -0.1348, -0.0593, -0.0420,  0.1541,  0.0957, -0.0808, -0.1867,  0.1297,\n",
      "        -0.1272,  0.0821, -0.0051, -0.0559,  0.0522, -0.1244, -0.0425,  0.1899,\n",
      "        -0.0498,  0.0286, -0.1401, -0.0118,  0.0197,  0.0641, -0.0897, -0.2164,\n",
      "        -0.0785, -0.0367, -0.2644, -0.0186, -0.2175,  0.1131, -0.0312, -0.0683,\n",
      "         0.0414,  0.0643, -0.0224, -0.0519, -0.2385, -0.3741, -0.2496,  0.0274])), ('hidden_layers.2.weight', tensor([[-0.0282, -0.1024, -0.1422,  ...,  0.0321,  0.0231, -0.0188],\n",
      "        [-0.2209, -0.0153,  0.0461,  ...,  0.0091, -0.0386, -0.0338],\n",
      "        [-0.0290,  0.0184,  0.0451,  ..., -0.0744,  0.0507, -0.0692],\n",
      "        ...,\n",
      "        [ 0.0355,  0.0006, -0.0955,  ..., -0.0326, -0.0700, -0.0165],\n",
      "        [ 0.1187,  0.0313, -0.0471,  ...,  0.1241, -0.0779,  0.1553],\n",
      "        [-0.1854,  0.0424, -0.0093,  ...,  0.0873, -0.1755,  0.0328]])), ('hidden_layers.2.bias', tensor([-0.1188,  0.2113,  0.0523,  0.1649,  0.4272,  0.5502, -0.0656,  0.2185,\n",
      "         0.0175,  0.1356,  0.1132,  0.1979,  0.2056,  0.3417,  0.2277,  0.2733,\n",
      "         0.1622,  0.3714,  0.0848,  0.3489,  0.4690,  0.4282,  0.2764,  0.0811,\n",
      "         0.3660,  0.0358,  0.1614, -0.0377, -0.2900, -0.0625, -0.0745,  0.4443,\n",
      "         0.1099,  0.1626, -0.1154,  0.4157,  0.2451,  0.0429,  0.0803,  0.0739,\n",
      "         0.1551,  0.3727, -0.0449,  0.1752,  0.2156,  0.3772,  0.0761,  0.2747,\n",
      "        -0.0041,  0.0372, -0.0040, -0.1331,  0.1429,  0.0272, -0.1347, -0.0840,\n",
      "         0.4215,  0.1483,  0.5461,  0.0249,  0.4771,  0.3240, -0.0697,  0.2708,\n",
      "        -0.0403, -0.0645,  0.2892,  0.0141, -0.0865,  0.3076,  0.0532,  0.2118,\n",
      "         0.3761, -0.2433,  0.3999,  0.0010,  0.0702,  0.2361,  0.0285, -0.0613,\n",
      "         0.1515,  0.1404,  0.2230,  0.2083,  0.3089, -0.1941,  0.1255,  0.3878,\n",
      "         0.1895,  0.0254,  0.1802,  0.4590,  0.2411,  0.1870,  0.4978, -0.1373,\n",
      "        -0.2660,  0.4401,  0.1939, -0.1719,  0.2715, -0.0584,  0.3083,  0.1120,\n",
      "        -0.1270, -0.0051,  0.4818,  0.2697,  0.1411,  0.1324,  0.0421,  0.4156,\n",
      "         0.3369,  0.2960,  0.1659, -0.0606,  0.0073,  0.1705,  0.4042,  0.1857,\n",
      "         0.0828, -0.2443,  0.3960, -0.0199,  0.1139,  0.0645,  0.4632,  0.3564])), ('output.weight', tensor([[ 0.0236, -0.1976, -0.0908,  ..., -0.0423, -0.0716,  0.0437],\n",
      "        [-0.0927, -0.1151, -0.2115,  ..., -0.0901, -0.1966,  0.0042],\n",
      "        [ 0.0050,  0.0209, -0.0783,  ..., -0.1045,  0.0805, -0.0423],\n",
      "        ...,\n",
      "        [ 0.0136,  0.0228,  0.0088,  ...,  0.0526, -0.1658, -0.2097],\n",
      "        [ 0.0677, -0.1270, -0.0384,  ..., -0.0759, -0.1074, -0.0016],\n",
      "        [-0.0094,  0.0535, -0.0643,  ...,  0.0269, -0.3417, -0.3675]])), ('output.bias', tensor([-0.1623, -0.7062,  0.1708,  0.3090,  0.1257,  0.1218,  0.1092, -0.0323,\n",
      "        -0.0722, -0.3215]))])\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('checkpoint.pth')\n",
    "print(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'input_size': 784,\n",
    "              'output_size': 10,\n",
    "              'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
    "              'state_dict': model.state_dict()}\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_size': 784, 'output_size': 10, 'hidden_layers': [400, 200, 100], 'state_dict': OrderedDict([('hidden_layers.0.weight', tensor([[ 0.0298,  0.0007,  0.0003,  ..., -0.0230,  0.0112,  0.0283],\n",
      "        [-0.0247, -0.0108, -0.0046,  ...,  0.0356,  0.0109,  0.0020],\n",
      "        [-0.0005, -0.0132,  0.0271,  ...,  0.0128, -0.0196, -0.0283],\n",
      "        ...,\n",
      "        [ 0.0186,  0.0096,  0.0310,  ...,  0.0023,  0.0218,  0.0335],\n",
      "        [-0.0310,  0.0234, -0.0212,  ..., -0.0200,  0.0061,  0.0255],\n",
      "        [-0.0141,  0.0022,  0.0122,  ...,  0.0031,  0.0315,  0.0287]])), ('hidden_layers.0.bias', tensor([-9.8592e-03,  1.7657e-02, -2.4308e-02,  2.9542e-02,  2.2225e-02,\n",
      "         2.2188e-02,  2.8922e-02, -2.7250e-02, -1.7284e-02,  1.5944e-03,\n",
      "         3.2415e-02,  2.6884e-02,  2.5314e-02, -2.8403e-02,  1.6805e-04,\n",
      "         6.1474e-03, -5.1311e-03, -1.5607e-02, -2.9765e-02, -1.1842e-02,\n",
      "        -1.5517e-02, -1.0225e-02, -9.3646e-03, -2.0117e-02, -1.2496e-02,\n",
      "        -9.6756e-03,  3.7048e-03, -1.6116e-03, -2.9292e-02,  1.1366e-02,\n",
      "        -3.3986e-02,  1.8457e-02,  2.9728e-02,  1.3001e-04, -1.8106e-02,\n",
      "         4.9314e-03, -1.9493e-02,  2.0675e-02,  1.5455e-02,  2.4101e-02,\n",
      "         1.3658e-02, -2.5804e-02,  3.3215e-03,  8.3926e-03,  5.6906e-03,\n",
      "         2.7368e-02, -9.2857e-03, -1.4879e-03,  5.2504e-03, -1.5450e-03,\n",
      "         9.7322e-03, -1.3342e-02, -1.7873e-02, -6.5818e-03,  1.7865e-02,\n",
      "         1.4184e-02, -2.7966e-03,  2.4861e-02, -4.5592e-03, -7.5592e-03,\n",
      "         9.4208e-04,  3.3995e-03,  2.8882e-02,  6.0452e-03,  1.1246e-03,\n",
      "        -1.0327e-02, -3.7399e-03, -3.0379e-02, -1.4322e-02,  1.6121e-02,\n",
      "         8.5804e-03,  3.1342e-02, -1.2039e-02,  2.3273e-02,  9.4916e-03,\n",
      "         6.7734e-03, -7.9034e-04,  6.5499e-03, -1.7448e-02,  1.8347e-02,\n",
      "         1.7104e-02, -1.7067e-02,  1.7649e-02,  2.8035e-03, -1.0821e-02,\n",
      "         1.3979e-02,  2.3524e-02, -2.1850e-02, -2.4066e-02,  5.1246e-03,\n",
      "        -2.5185e-02, -2.5694e-02,  7.2299e-03,  2.2392e-02, -4.4699e-03,\n",
      "        -2.4143e-02, -1.4361e-02,  2.8053e-02,  4.8583e-04,  2.4929e-02,\n",
      "        -5.5433e-03, -2.7321e-02,  6.5635e-03, -1.1359e-02,  3.4070e-02,\n",
      "         3.1175e-02,  2.9801e-02, -3.1418e-02, -2.8762e-02, -2.8260e-02,\n",
      "        -1.1844e-02, -1.0237e-02, -3.3229e-02, -1.0329e-02, -2.5095e-02,\n",
      "         3.8471e-03, -6.4613e-03, -1.0036e-02,  2.8530e-02, -2.4156e-02,\n",
      "        -1.6260e-03, -2.4349e-02, -1.8652e-02, -2.0819e-02, -4.6096e-03,\n",
      "        -4.7746e-03, -1.7320e-02,  1.8047e-02,  1.2587e-02,  1.8491e-02,\n",
      "         1.3918e-02, -3.3358e-02,  3.3284e-02,  3.1867e-02, -3.2287e-02,\n",
      "        -2.3028e-02,  1.5250e-02,  3.5065e-02,  1.8019e-02, -1.3955e-02,\n",
      "        -2.8817e-03,  2.4855e-02, -2.8039e-02,  6.4754e-03,  3.1210e-02,\n",
      "         1.7660e-02, -2.7219e-02,  2.9106e-02,  1.3573e-03, -1.9853e-03,\n",
      "         3.4053e-02,  1.3069e-02,  2.4483e-02, -6.8503e-03,  2.5002e-02,\n",
      "         4.6072e-03, -2.7885e-02, -1.4669e-02, -2.2506e-02, -2.8960e-02,\n",
      "         2.4100e-02, -2.3381e-02,  1.1832e-02,  4.8453e-03,  7.8569e-03,\n",
      "        -2.6158e-02, -1.2772e-02,  2.7554e-02,  1.3793e-02,  1.9517e-02,\n",
      "        -5.4207e-03, -2.9427e-02,  3.1393e-02,  2.0529e-02, -3.1554e-03,\n",
      "         2.9796e-02,  1.9369e-02, -2.1662e-02, -1.3108e-02, -3.5461e-02,\n",
      "         1.9995e-02,  3.4784e-02, -3.1993e-02,  1.2370e-02,  1.2899e-02,\n",
      "         2.8088e-03,  3.8726e-03,  3.3200e-02, -2.2407e-02,  1.6278e-02,\n",
      "         2.4132e-02, -1.4176e-02, -2.9423e-02, -2.2980e-02,  1.0862e-02,\n",
      "         1.0681e-02,  6.5198e-03,  1.2409e-02,  1.3926e-02, -3.5708e-02,\n",
      "         2.4504e-02, -2.6919e-02,  3.2673e-02,  4.3302e-03,  2.5630e-03,\n",
      "        -6.3719e-03, -1.4726e-02, -3.5021e-02, -2.1575e-02,  8.6884e-03,\n",
      "         2.0693e-03,  2.3545e-02, -2.7571e-02,  9.9647e-03, -1.6061e-02,\n",
      "         1.2591e-02, -2.0104e-02,  1.4447e-02, -3.2425e-02, -9.4687e-03,\n",
      "        -1.4002e-02, -1.5487e-02,  3.1374e-02, -2.3101e-03,  3.5241e-02,\n",
      "        -1.6612e-02,  3.3373e-02, -1.9483e-02, -7.0095e-03, -2.3278e-02,\n",
      "         1.0276e-02,  1.4932e-02,  8.2944e-03,  3.2331e-02, -6.2681e-03,\n",
      "        -1.0999e-02, -2.8628e-02,  3.2903e-02, -9.1593e-03,  1.9086e-02,\n",
      "         1.7270e-04, -8.2087e-05, -1.5947e-02,  3.0830e-02, -1.9643e-02,\n",
      "        -9.1042e-03, -3.4456e-02,  1.4355e-02,  1.8085e-02,  1.7025e-02,\n",
      "         7.8334e-03, -2.4190e-02,  3.4460e-02,  2.3412e-03,  1.2716e-02,\n",
      "        -2.8160e-02, -1.4499e-02, -1.3175e-03,  1.5029e-02, -5.4873e-03,\n",
      "        -2.5511e-02,  1.9880e-03, -1.6847e-02, -2.7251e-02,  3.4085e-02,\n",
      "        -1.3525e-02, -2.4347e-02,  2.0734e-02,  2.8337e-02, -2.1280e-03,\n",
      "        -8.9401e-04,  9.8448e-03, -3.0332e-02,  1.7481e-02,  7.9972e-03,\n",
      "        -2.0827e-02,  3.0741e-03,  3.3793e-02, -2.6348e-02, -9.9333e-04,\n",
      "         3.1373e-02,  3.2240e-02, -3.6323e-03,  1.4056e-02, -1.1218e-02,\n",
      "         5.2580e-03, -1.1402e-02,  1.6614e-02, -1.5123e-03, -2.7960e-02,\n",
      "         2.6062e-03,  1.4058e-02, -1.9209e-02,  1.6070e-02, -7.2920e-03,\n",
      "        -6.7786e-03,  2.4424e-02,  3.0011e-02,  2.6238e-02, -5.1412e-03,\n",
      "         3.5122e-02, -2.6586e-02, -7.1045e-03,  1.5211e-02, -2.4951e-02,\n",
      "         1.9217e-02,  3.4846e-02,  9.0813e-03,  1.4171e-03, -2.2160e-02,\n",
      "         2.7255e-02,  1.3705e-02, -3.2662e-02,  9.2832e-03,  2.9543e-03,\n",
      "        -1.4368e-03, -2.2364e-02, -3.3700e-02, -2.4188e-02, -1.8176e-02,\n",
      "         3.2474e-02, -2.4532e-02,  6.0297e-03,  3.7087e-03,  2.7613e-02,\n",
      "        -3.0099e-02,  2.0430e-02, -8.7195e-03, -1.7855e-02,  3.1907e-02,\n",
      "        -1.4842e-02, -8.2080e-03, -3.1243e-02,  2.3005e-02,  2.4056e-02,\n",
      "        -2.6541e-02, -1.5346e-02, -2.7354e-02, -3.3597e-02,  2.7640e-02,\n",
      "        -2.6775e-02, -1.6564e-02,  1.3383e-02, -1.8177e-02, -1.3293e-02,\n",
      "        -1.4150e-02,  1.6645e-03,  3.3089e-02,  1.5615e-02,  3.3087e-02,\n",
      "        -1.8880e-02,  3.3853e-02,  3.4457e-02,  2.1035e-03, -1.4738e-02,\n",
      "         3.2202e-02, -3.4539e-02, -1.7930e-02, -8.0302e-03,  2.1083e-02,\n",
      "        -6.0350e-03,  3.3043e-02,  6.6708e-04, -3.0217e-02, -3.0543e-02,\n",
      "         3.1825e-02, -4.8816e-05,  3.5170e-02, -2.8012e-02, -9.6303e-03,\n",
      "        -1.3497e-02, -3.0798e-02, -2.3762e-02,  6.7100e-04,  1.0859e-02,\n",
      "         3.1799e-02, -3.5521e-02,  2.6855e-02,  1.0351e-02,  3.2339e-02,\n",
      "        -1.4126e-02, -5.5745e-03,  1.4755e-02, -3.1824e-02, -1.9574e-02,\n",
      "         1.4994e-03,  1.0835e-02, -1.6875e-02, -2.9620e-02, -3.3065e-02,\n",
      "        -1.6309e-02, -3.4817e-02,  1.8146e-03,  8.8841e-03, -1.6853e-02,\n",
      "         1.9722e-02, -1.4363e-02,  3.2131e-02,  1.6882e-02, -1.6661e-02])), ('hidden_layers.1.weight', tensor([[ 0.0237,  0.0271, -0.0498,  ..., -0.0382, -0.0355, -0.0471],\n",
      "        [ 0.0224, -0.0315, -0.0462,  ...,  0.0195, -0.0210, -0.0478],\n",
      "        [-0.0250, -0.0330,  0.0395,  ..., -0.0178,  0.0177,  0.0457],\n",
      "        ...,\n",
      "        [-0.0124,  0.0328,  0.0047,  ...,  0.0002,  0.0198,  0.0437],\n",
      "        [-0.0258,  0.0154,  0.0344,  ..., -0.0456,  0.0287,  0.0303],\n",
      "        [-0.0296, -0.0470,  0.0482,  ..., -0.0343, -0.0077, -0.0171]])), ('hidden_layers.1.bias', tensor([-0.0056,  0.0104, -0.0053, -0.0296,  0.0274,  0.0021,  0.0224, -0.0340,\n",
      "        -0.0156, -0.0281, -0.0291,  0.0323,  0.0262, -0.0383, -0.0137, -0.0417,\n",
      "        -0.0164,  0.0455,  0.0431,  0.0330,  0.0024, -0.0462, -0.0309,  0.0036,\n",
      "         0.0344,  0.0235, -0.0086,  0.0415,  0.0141, -0.0293,  0.0107,  0.0154,\n",
      "         0.0089, -0.0366,  0.0303,  0.0142,  0.0005,  0.0218,  0.0196,  0.0116,\n",
      "         0.0065, -0.0180, -0.0377, -0.0161,  0.0493, -0.0468,  0.0162,  0.0491,\n",
      "        -0.0397,  0.0374,  0.0244, -0.0252,  0.0004, -0.0357, -0.0259, -0.0209,\n",
      "        -0.0038, -0.0136, -0.0056,  0.0244,  0.0380,  0.0314,  0.0007, -0.0246,\n",
      "        -0.0033,  0.0434,  0.0131, -0.0225, -0.0440,  0.0254,  0.0059,  0.0193,\n",
      "         0.0359, -0.0113, -0.0102, -0.0304,  0.0394,  0.0132,  0.0133, -0.0335,\n",
      "         0.0282, -0.0156,  0.0424, -0.0417,  0.0344,  0.0191, -0.0135, -0.0225,\n",
      "         0.0466,  0.0184,  0.0224, -0.0433, -0.0336,  0.0456, -0.0086, -0.0030,\n",
      "        -0.0139, -0.0418, -0.0280, -0.0468,  0.0233, -0.0121, -0.0138, -0.0146,\n",
      "        -0.0269,  0.0224,  0.0431,  0.0351, -0.0269, -0.0016,  0.0439,  0.0242,\n",
      "         0.0146,  0.0001,  0.0364, -0.0112, -0.0460, -0.0073,  0.0050,  0.0342,\n",
      "        -0.0462,  0.0181, -0.0396,  0.0093,  0.0091,  0.0149, -0.0321,  0.0186,\n",
      "         0.0095,  0.0265, -0.0375,  0.0179,  0.0053,  0.0052,  0.0049, -0.0188,\n",
      "        -0.0037,  0.0278,  0.0142, -0.0470,  0.0430, -0.0337, -0.0112, -0.0275,\n",
      "        -0.0136,  0.0106, -0.0287,  0.0326,  0.0039,  0.0204,  0.0035,  0.0087,\n",
      "        -0.0319,  0.0073,  0.0059, -0.0256,  0.0340,  0.0353, -0.0363, -0.0084,\n",
      "         0.0268, -0.0016, -0.0051, -0.0327, -0.0063, -0.0388, -0.0215,  0.0308,\n",
      "         0.0018,  0.0051,  0.0214, -0.0074, -0.0463,  0.0166,  0.0451, -0.0287,\n",
      "         0.0084,  0.0391, -0.0389,  0.0203,  0.0491, -0.0255,  0.0476,  0.0345,\n",
      "         0.0458, -0.0344,  0.0196, -0.0405,  0.0093,  0.0156,  0.0377,  0.0197,\n",
      "         0.0499, -0.0291, -0.0202, -0.0209,  0.0030, -0.0078,  0.0455, -0.0209])), ('hidden_layers.2.weight', tensor([[-0.0280, -0.0689, -0.0480,  ...,  0.0690, -0.0573, -0.0394],\n",
      "        [ 0.0147, -0.0469, -0.0314,  ..., -0.0563,  0.0462,  0.0274],\n",
      "        [-0.0638,  0.0504,  0.0629,  ...,  0.0138, -0.0092, -0.0213],\n",
      "        ...,\n",
      "        [-0.0352,  0.0045,  0.0596,  ..., -0.0266, -0.0341,  0.0644],\n",
      "        [ 0.0609, -0.0515,  0.0606,  ...,  0.0544, -0.0640,  0.0411],\n",
      "        [-0.0303, -0.0101,  0.0655,  ...,  0.0557, -0.0430, -0.0292]])), ('hidden_layers.2.bias', tensor([ 0.0296,  0.0245, -0.0121,  0.0623,  0.0491,  0.0085,  0.0192,  0.0315,\n",
      "         0.0171, -0.0029, -0.0557, -0.0700,  0.0488, -0.0012, -0.0620, -0.0676,\n",
      "         0.0168,  0.0456,  0.0486, -0.0181, -0.0227, -0.0613,  0.0499, -0.0046,\n",
      "         0.0158,  0.0284,  0.0051, -0.0125, -0.0210, -0.0639,  0.0318,  0.0453,\n",
      "        -0.0093,  0.0276, -0.0329,  0.0120,  0.0093, -0.0260, -0.0344, -0.0027,\n",
      "         0.0033, -0.0053,  0.0678,  0.0366, -0.0382,  0.0167, -0.0198, -0.0591,\n",
      "         0.0292, -0.0264, -0.0021, -0.0240, -0.0449,  0.0642,  0.0361, -0.0248,\n",
      "        -0.0326, -0.0157, -0.0583,  0.0327,  0.0637, -0.0151, -0.0009,  0.0217,\n",
      "         0.0482, -0.0140,  0.0632,  0.0155, -0.0567,  0.0586,  0.0206, -0.0090,\n",
      "        -0.0375,  0.0628,  0.0204,  0.0324, -0.0286,  0.0024, -0.0631, -0.0169,\n",
      "        -0.0688, -0.0600,  0.0603,  0.0471, -0.0651, -0.0219,  0.0385, -0.0246,\n",
      "        -0.0684,  0.0137, -0.0064,  0.0122,  0.0037,  0.0498, -0.0245, -0.0200,\n",
      "        -0.0616, -0.0530,  0.0577, -0.0222])), ('output.weight', tensor([[ 3.7388e-02, -9.1598e-02, -7.2959e-02, -5.5195e-03, -8.3296e-02,\n",
      "          8.9564e-02,  4.5970e-03,  2.1673e-02,  1.7340e-02,  9.7433e-02,\n",
      "         -6.1765e-02, -7.7735e-02, -8.8545e-02, -8.7316e-02, -1.2983e-03,\n",
      "         -7.6998e-02,  8.4828e-02, -8.6973e-02,  9.1902e-02,  7.4764e-02,\n",
      "         -1.6346e-02,  6.2309e-04, -3.3798e-02, -2.4531e-02, -8.9758e-02,\n",
      "          9.2736e-02, -8.9875e-02,  1.5333e-02,  5.9686e-02,  6.6302e-02,\n",
      "         -6.8138e-02,  8.6624e-03, -2.2740e-02,  6.2062e-02, -3.6662e-02,\n",
      "          6.0166e-02, -7.0819e-03,  2.3683e-02, -3.1713e-02, -8.5159e-03,\n",
      "         -6.9852e-03,  1.6479e-03,  6.4606e-02, -2.4417e-02, -7.4943e-02,\n",
      "         -8.3782e-02,  4.5974e-02, -4.3272e-02, -9.3116e-02,  3.9035e-02,\n",
      "         -5.2096e-02, -7.6047e-02, -1.5138e-03,  6.0020e-02, -5.7343e-02,\n",
      "          9.6659e-02, -1.9637e-02,  7.2413e-02,  4.8320e-02,  6.1255e-03,\n",
      "          6.9225e-02, -9.8926e-02,  1.6297e-02,  2.4047e-02, -2.6212e-02,\n",
      "          9.2229e-02, -5.1896e-02,  2.5935e-02, -2.4711e-02,  2.7763e-03,\n",
      "          6.4899e-02,  4.6256e-02, -5.7608e-02,  7.2198e-02,  6.9626e-02,\n",
      "         -2.8625e-02,  2.4178e-02,  4.4208e-02, -5.4912e-02,  9.8585e-02,\n",
      "         -8.7589e-02, -7.6144e-02, -3.4263e-02, -5.7522e-02, -9.7288e-02,\n",
      "          9.7310e-02,  8.2213e-02,  4.9045e-02, -2.4024e-03,  6.1888e-02,\n",
      "          8.9786e-02, -4.3337e-02,  7.8199e-02, -8.4480e-02,  8.0435e-02,\n",
      "         -4.2118e-02,  5.2378e-03, -7.0688e-02, -8.5338e-02, -7.9588e-02],\n",
      "        [-3.6334e-02,  6.1998e-02, -6.4174e-02, -9.8689e-02, -5.6866e-02,\n",
      "          4.4930e-02,  7.0153e-02, -3.9804e-02,  8.5926e-02, -9.0791e-02,\n",
      "          4.2877e-02,  1.4148e-02,  2.1198e-02,  3.0144e-03,  6.7487e-02,\n",
      "          5.7865e-02,  6.0901e-02,  6.1317e-02,  4.1901e-02,  8.6761e-02,\n",
      "          1.3340e-03,  4.4182e-02,  3.2549e-03,  9.7958e-02,  4.7021e-02,\n",
      "          6.5057e-04,  1.9266e-02,  8.0809e-02, -5.7874e-02,  8.7395e-02,\n",
      "          2.7923e-02,  8.8558e-02,  2.7726e-02,  3.0576e-02, -1.0583e-02,\n",
      "         -5.1367e-02,  8.1826e-02,  1.7303e-02, -6.8962e-02,  6.4738e-02,\n",
      "          9.8493e-02,  4.4613e-02, -4.9437e-02, -9.4476e-02, -4.2390e-02,\n",
      "          2.5746e-02,  2.5991e-02,  2.1954e-02,  5.1392e-02, -9.6622e-02,\n",
      "          2.7303e-02, -5.2443e-02,  4.2546e-02,  4.8569e-02, -4.6220e-02,\n",
      "          5.2266e-02, -4.5993e-02,  7.0800e-02,  4.5972e-02,  3.8571e-02,\n",
      "         -7.7113e-02, -1.5835e-02, -9.7686e-02, -9.5404e-02, -4.5080e-03,\n",
      "         -8.0690e-02, -5.7460e-02,  1.1799e-02,  6.7533e-03, -7.2052e-02,\n",
      "         -7.4835e-02,  4.5863e-02,  9.8411e-02, -2.0099e-02, -2.7114e-02,\n",
      "          9.4527e-02, -1.5276e-02, -1.9112e-02, -9.4218e-02, -2.2033e-03,\n",
      "          2.3205e-02, -8.8516e-02,  4.6754e-03, -6.0263e-02,  1.9186e-02,\n",
      "         -5.4584e-02, -8.1496e-03,  4.6443e-02,  8.1833e-02, -4.5881e-02,\n",
      "         -5.2388e-02, -8.1009e-02, -7.9097e-02, -8.1850e-02, -3.7051e-03,\n",
      "         -4.6742e-02, -1.2443e-02, -8.5960e-02, -5.7034e-02,  9.1886e-02],\n",
      "        [-4.6250e-02,  3.5433e-02, -4.3322e-03, -3.2076e-02,  2.9594e-02,\n",
      "          2.1704e-02,  7.7824e-02, -4.5256e-02, -6.0170e-02,  6.0902e-02,\n",
      "          4.0163e-02,  4.5632e-02, -9.9433e-02, -2.3518e-02,  6.1657e-02,\n",
      "          1.1232e-03, -8.7082e-04, -1.7249e-02, -6.2931e-02,  6.8282e-02,\n",
      "          2.6425e-02, -5.4369e-03, -9.4083e-02, -6.3238e-02, -9.1580e-02,\n",
      "          3.1573e-02, -7.4298e-02,  1.6819e-02,  5.2110e-02,  1.2260e-03,\n",
      "         -5.5380e-02, -4.5153e-03,  2.8619e-02,  1.9348e-02,  8.3257e-02,\n",
      "         -1.0674e-02,  9.3577e-02,  5.1143e-02, -6.6890e-03, -5.4478e-02,\n",
      "          9.6960e-02, -2.6257e-02, -2.3573e-02,  6.0961e-02,  2.6427e-02,\n",
      "         -5.8996e-02, -6.2242e-02,  2.4292e-02,  5.3018e-02,  9.9593e-02,\n",
      "          3.5526e-02,  3.6069e-02, -2.7617e-02,  3.5004e-02,  8.6591e-02,\n",
      "          6.4232e-02,  3.5197e-02, -7.5221e-03,  6.0758e-02, -7.4295e-02,\n",
      "          9.6873e-02, -7.3791e-02, -9.2853e-02,  3.7077e-02, -6.6021e-02,\n",
      "          6.3687e-02, -7.1432e-02,  5.1697e-02, -7.6110e-02,  8.8595e-02,\n",
      "         -8.9778e-04, -6.8756e-02,  7.8549e-02,  8.6471e-02, -4.5650e-02,\n",
      "          9.3428e-02,  4.9400e-03,  9.6977e-02,  3.8725e-02, -9.0481e-02,\n",
      "          4.3410e-02,  8.3188e-02,  8.1928e-02,  7.8979e-02,  1.9650e-02,\n",
      "         -6.5002e-02, -2.2292e-02,  4.1474e-02, -1.1271e-02, -9.5096e-02,\n",
      "          1.8293e-02,  2.6932e-02,  8.4405e-02, -4.0009e-02, -5.9330e-02,\n",
      "         -7.9718e-02,  6.2347e-03, -8.0022e-02,  6.6842e-02, -2.7102e-02],\n",
      "        [ 7.1457e-02,  8.7239e-02,  7.7175e-03, -2.4045e-02, -2.9259e-02,\n",
      "          3.0055e-02, -6.4102e-02,  8.0938e-02,  1.7380e-02, -5.2660e-02,\n",
      "         -1.8964e-02, -9.9463e-02, -5.6363e-02, -5.7061e-02, -3.3003e-02,\n",
      "          9.3159e-02,  1.8048e-02, -5.2133e-02, -4.8152e-03, -2.4657e-03,\n",
      "          2.9709e-02, -8.2249e-02, -6.3988e-02,  3.5225e-02, -1.7476e-02,\n",
      "          3.4756e-03,  3.7725e-02,  3.3150e-02,  2.8601e-02, -6.3781e-02,\n",
      "         -8.8951e-02, -9.9210e-02,  3.4810e-02,  5.0281e-02, -6.5883e-02,\n",
      "         -6.7243e-02, -1.7542e-02, -9.3786e-02, -9.5968e-02,  8.5110e-02,\n",
      "         -5.2352e-02,  1.0445e-02, -4.9002e-02,  8.4818e-02, -3.0573e-02,\n",
      "          8.0032e-02,  2.3554e-02, -7.1172e-02, -7.7484e-02, -5.3141e-02,\n",
      "         -1.2775e-02,  9.3578e-02,  5.5334e-02, -6.4295e-02,  2.4668e-02,\n",
      "          5.0553e-02,  4.2011e-02, -8.5362e-02,  4.0986e-02, -8.8994e-02,\n",
      "         -2.6316e-03,  7.3578e-03, -8.2988e-02, -9.7140e-02,  9.6137e-02,\n",
      "          9.1961e-02, -9.9000e-02, -5.1492e-02, -1.8343e-02, -2.7451e-02,\n",
      "          6.7846e-02,  4.6144e-02, -7.0463e-02,  4.1264e-02, -9.9145e-02,\n",
      "          3.4205e-02,  7.2625e-02, -4.9998e-02, -8.1393e-02,  7.5662e-02,\n",
      "         -2.1637e-02, -4.1000e-02,  8.7649e-02,  6.9661e-02,  6.1369e-02,\n",
      "         -8.2560e-02, -5.9687e-02, -9.2198e-02,  6.1599e-02,  4.1341e-02,\n",
      "         -7.5201e-03,  4.6460e-02,  8.4926e-02, -7.1177e-02,  3.0300e-02,\n",
      "          9.4014e-02,  9.5353e-02, -4.5523e-02,  9.9446e-02,  1.3497e-02],\n",
      "        [ 8.7429e-02, -3.0468e-02,  6.4541e-02,  2.5215e-02, -4.0921e-02,\n",
      "         -8.0536e-03, -1.9936e-02,  3.8948e-02, -7.6962e-02,  6.0520e-02,\n",
      "         -9.9247e-02,  4.4799e-02,  7.1750e-02,  3.4506e-02,  8.1140e-02,\n",
      "         -6.8198e-02, -1.8932e-02,  1.7651e-02, -7.8642e-02, -7.9509e-02,\n",
      "         -9.5123e-02,  8.5047e-02,  3.1328e-02,  6.2007e-03, -3.4899e-02,\n",
      "          2.4477e-04, -3.5564e-02, -4.2467e-02,  9.6684e-02, -2.5916e-02,\n",
      "         -7.4083e-02, -6.4079e-02, -3.5634e-02, -3.6840e-02, -9.5580e-03,\n",
      "          8.5917e-02, -5.3907e-02,  7.3406e-02, -4.0613e-02, -8.1250e-02,\n",
      "         -4.1912e-02, -1.4026e-02,  4.9485e-02,  4.8254e-03,  4.4737e-02,\n",
      "          4.7000e-02,  1.5989e-02,  1.5257e-02,  6.8540e-02, -4.0446e-02,\n",
      "          4.6895e-02,  6.7502e-02,  9.6029e-02,  6.7071e-02, -9.6432e-02,\n",
      "          2.2795e-02,  2.2583e-02, -1.8715e-02, -5.2809e-02,  2.9835e-02,\n",
      "          7.3935e-02, -3.6394e-02,  5.7840e-02,  3.6516e-02,  9.6870e-02,\n",
      "         -9.6660e-02, -9.6027e-02,  3.1369e-02,  4.8326e-02,  8.2411e-02,\n",
      "         -4.8668e-02,  3.7567e-03, -3.5938e-03,  5.2837e-02,  5.3686e-02,\n",
      "          6.8178e-03, -9.8048e-02,  4.0987e-03,  5.9793e-02,  2.9115e-02,\n",
      "         -3.8613e-02,  4.8745e-02, -2.8035e-02, -2.8802e-02, -1.2703e-02,\n",
      "         -5.8350e-02, -9.5034e-02, -5.9368e-02,  9.5358e-02, -3.2260e-02,\n",
      "          5.2571e-02,  6.5779e-02, -2.8352e-02,  9.4539e-02, -6.6071e-02,\n",
      "          8.4935e-02, -1.5301e-02,  2.9423e-02, -8.5036e-02, -1.0408e-02],\n",
      "        [-3.7369e-02,  8.6004e-02, -1.6696e-02,  2.4759e-02, -5.2147e-02,\n",
      "         -7.2743e-02,  1.0806e-02, -3.3367e-02, -7.0637e-03, -2.2557e-03,\n",
      "          1.0305e-03, -1.4720e-02,  1.0681e-02,  1.3291e-02, -8.7691e-02,\n",
      "         -4.3348e-02, -7.7492e-02, -5.2431e-02, -2.1446e-02,  9.3513e-02,\n",
      "         -5.2670e-02, -2.6895e-02,  6.0344e-02,  3.4909e-02,  6.7763e-02,\n",
      "          8.8995e-02, -8.4180e-03,  7.4446e-02, -3.9894e-02, -6.9834e-05,\n",
      "         -3.5073e-02,  7.1010e-02, -1.5601e-02,  6.5147e-02, -2.4025e-02,\n",
      "         -1.5286e-02,  8.3158e-02, -2.1025e-02,  6.4590e-02,  3.0577e-02,\n",
      "         -5.9815e-02,  5.8164e-02,  2.7515e-02, -7.8398e-02, -7.8614e-02,\n",
      "         -2.3836e-02,  1.3943e-02,  3.6358e-02,  9.7596e-02, -1.1777e-02,\n",
      "          5.3240e-02,  9.9329e-02,  2.1634e-03,  7.7539e-02,  5.8711e-03,\n",
      "          5.6768e-03,  4.6461e-02, -5.9140e-02,  4.2297e-02, -7.7150e-03,\n",
      "          6.4984e-02,  4.5143e-02,  2.5202e-02, -4.4708e-02, -7.6502e-02,\n",
      "          3.1034e-02,  7.0582e-02,  7.6078e-02, -8.7511e-02,  9.4199e-02,\n",
      "          4.4817e-02,  4.5876e-02,  7.8429e-02,  2.5480e-02,  9.7826e-03,\n",
      "          2.1089e-02, -7.6240e-02,  7.4835e-02,  3.6793e-02,  6.7944e-02,\n",
      "          3.5394e-02, -3.5487e-05, -7.2477e-02, -3.6092e-02, -3.9825e-02,\n",
      "          3.7159e-03,  3.8189e-02,  4.3218e-02, -7.4282e-02,  5.9916e-02,\n",
      "         -9.8336e-02, -9.9144e-02, -5.4377e-02,  7.3278e-02,  1.7444e-02,\n",
      "          5.4941e-02,  2.1741e-02,  7.4314e-02, -9.5570e-02,  1.1972e-02],\n",
      "        [ 7.3194e-02, -1.2736e-02, -5.5012e-02,  3.7866e-02, -7.9691e-02,\n",
      "         -2.0431e-02,  2.2672e-03,  6.4274e-02, -4.5988e-02, -2.8082e-02,\n",
      "         -9.1686e-02, -8.6681e-02,  4.1797e-02,  5.6251e-03,  5.3972e-02,\n",
      "          9.6985e-02,  4.9821e-02,  8.0090e-02, -8.2315e-02,  8.6956e-02,\n",
      "         -6.9761e-02,  7.8408e-02, -6.6534e-02, -8.8457e-02, -2.6408e-02,\n",
      "          7.9698e-03, -2.2935e-02, -4.1828e-02, -3.4617e-02,  5.3252e-02,\n",
      "         -7.8476e-02, -9.2908e-03, -1.0412e-02, -9.5676e-02, -9.9743e-02,\n",
      "         -4.6644e-02,  8.1430e-02,  1.2869e-02,  3.9861e-03,  8.4302e-02,\n",
      "          8.7950e-02, -4.4629e-02, -6.3627e-02, -5.8387e-02,  5.5896e-02,\n",
      "          4.3233e-02, -7.6828e-03, -4.2755e-03, -1.5864e-03,  6.2831e-03,\n",
      "          9.8938e-02, -9.1853e-02,  9.6989e-02, -8.8593e-02,  8.4379e-02,\n",
      "         -3.8831e-03,  4.8017e-02, -7.8525e-02,  5.3034e-02,  8.5194e-02,\n",
      "          1.4124e-02, -4.1302e-02, -2.1780e-04, -1.2342e-02,  9.4153e-02,\n",
      "          6.5640e-02,  1.1978e-02, -9.4847e-02, -1.3763e-02, -5.5667e-02,\n",
      "         -9.3531e-02, -8.7825e-02,  3.9582e-03,  6.3566e-02, -2.5437e-02,\n",
      "         -7.8082e-04, -4.0150e-02,  6.6429e-03, -9.2540e-02,  9.0642e-02,\n",
      "         -8.7670e-03, -4.8106e-02, -4.0844e-02,  6.8399e-03, -8.2475e-02,\n",
      "         -9.1812e-02, -4.9238e-02, -3.8590e-02,  9.4447e-02, -8.0563e-02,\n",
      "          3.8864e-02,  3.9646e-03, -3.1113e-02, -4.8960e-02,  9.0180e-02,\n",
      "          1.4526e-02,  6.9822e-02, -7.7043e-02,  7.4245e-02, -9.0761e-02],\n",
      "        [ 5.8786e-02,  5.8596e-02, -4.3563e-03, -7.6786e-02, -3.7332e-02,\n",
      "          9.1749e-02, -7.9295e-02, -3.7777e-02,  7.2303e-04,  9.0189e-02,\n",
      "         -1.5198e-02,  8.0462e-02, -4.1548e-02,  4.4930e-02, -7.7431e-02,\n",
      "         -4.4210e-02,  3.0555e-02,  1.4638e-02,  6.9276e-02,  1.1376e-02,\n",
      "         -7.2105e-02,  7.8034e-02, -2.3234e-02,  7.8590e-02,  9.7087e-02,\n",
      "          5.2335e-02, -9.0270e-02,  9.3089e-02, -1.0492e-02, -1.6253e-02,\n",
      "          6.8218e-02, -4.0791e-02, -3.3158e-02, -6.9645e-02,  8.1989e-02,\n",
      "          6.6092e-02,  3.7967e-03,  7.9801e-02,  1.7769e-02, -2.5837e-02,\n",
      "          1.8271e-02, -2.8423e-02,  7.6943e-02, -4.7610e-02,  8.8497e-02,\n",
      "          7.3160e-02,  4.8569e-02, -7.9688e-03, -2.1462e-02, -3.6327e-02,\n",
      "         -1.5366e-02,  6.8367e-03,  7.2150e-02,  7.7453e-02,  8.4429e-02,\n",
      "          6.7168e-02, -2.1748e-02, -9.4373e-02,  1.0200e-02,  9.2503e-03,\n",
      "         -6.3198e-02, -8.4147e-02, -2.9385e-02, -8.2675e-02, -8.8473e-03,\n",
      "          2.1123e-02, -4.9312e-02,  3.1170e-02,  7.5414e-04,  3.4461e-02,\n",
      "         -9.0365e-02, -3.5334e-02, -1.0567e-02,  9.8127e-02, -4.8226e-02,\n",
      "         -6.7557e-02,  4.1386e-02, -7.2274e-02, -1.8577e-02, -6.6304e-02,\n",
      "         -4.3480e-02,  1.4403e-02, -6.5602e-02,  7.8672e-02,  9.7326e-02,\n",
      "          8.6314e-02,  5.2663e-02,  3.8011e-02, -6.1839e-02, -8.5238e-02,\n",
      "         -6.6444e-02, -3.5795e-02, -9.1811e-02, -8.4864e-03,  8.2030e-02,\n",
      "         -3.2325e-02, -9.0323e-02,  2.1058e-02,  5.5870e-02, -4.5803e-02],\n",
      "        [-6.8334e-02,  6.4323e-02,  1.9548e-02, -3.9629e-02, -9.0537e-02,\n",
      "          8.2099e-02, -8.4548e-02, -7.6676e-02, -7.1564e-02, -9.5493e-02,\n",
      "         -7.4255e-02,  5.7095e-02,  7.1798e-02, -6.4223e-02, -8.9164e-02,\n",
      "         -6.0806e-02, -9.7371e-03,  2.9872e-02, -6.5636e-02,  1.6022e-02,\n",
      "         -9.4724e-02, -2.8089e-02, -7.6073e-02, -7.3005e-02,  2.7075e-02,\n",
      "          8.0224e-02, -8.9844e-02, -6.4780e-02,  1.2480e-02, -8.3381e-02,\n",
      "         -2.3252e-02,  2.9140e-02,  6.8913e-02, -4.6217e-02,  5.6065e-02,\n",
      "         -8.8530e-03, -3.1301e-02,  7.6370e-02,  7.9639e-02, -8.4212e-02,\n",
      "          7.0994e-02,  2.4230e-02,  6.8779e-02,  9.9359e-02, -5.3750e-03,\n",
      "         -9.8764e-02, -6.9706e-02, -9.0164e-03, -2.6345e-02, -1.2696e-03,\n",
      "         -4.3687e-03, -8.4714e-03,  8.1267e-02, -6.7809e-02,  4.9687e-02,\n",
      "         -6.5452e-03, -6.7233e-02, -2.2370e-02,  3.0376e-02,  9.1232e-02,\n",
      "         -4.2964e-02, -9.7301e-02, -1.8990e-02,  4.2635e-02, -1.4863e-03,\n",
      "          8.2147e-02,  3.8206e-02,  2.1515e-02, -7.3267e-02,  4.8130e-02,\n",
      "          8.3164e-02, -4.1351e-02,  5.4868e-02,  4.4338e-02, -2.3266e-02,\n",
      "          4.4333e-02, -2.8080e-02, -3.6591e-02, -6.3354e-02, -2.7389e-02,\n",
      "         -6.1076e-02, -2.4834e-02, -3.5058e-02,  4.0876e-02, -1.8436e-02,\n",
      "         -6.3187e-02, -4.6612e-02,  9.9637e-02,  2.5449e-02,  8.1772e-02,\n",
      "         -5.6982e-02, -6.6296e-02, -3.7248e-02, -5.3810e-03, -3.6214e-02,\n",
      "         -2.9941e-02,  8.6950e-02,  8.0045e-03, -5.7699e-02, -6.8705e-02],\n",
      "        [ 4.4393e-02, -1.1038e-02,  9.5709e-02,  1.2405e-02, -1.5933e-02,\n",
      "          2.3199e-02, -2.6001e-02,  5.7617e-03, -2.1495e-02, -3.7847e-02,\n",
      "          7.2323e-02,  8.5617e-02,  4.0252e-02, -2.9884e-02,  9.7283e-02,\n",
      "         -7.9239e-02,  2.6356e-02, -5.7887e-02,  3.8226e-04,  8.1156e-02,\n",
      "          4.5854e-02, -8.2188e-02,  3.7514e-02, -2.0890e-02, -1.2156e-02,\n",
      "         -2.4015e-02,  2.9701e-02, -7.1849e-02,  6.0198e-02, -2.6587e-02,\n",
      "         -6.4497e-02,  8.8921e-02, -6.6080e-02, -8.2389e-02, -9.3363e-02,\n",
      "         -6.1376e-03,  6.8570e-02, -4.6229e-02, -8.7812e-02, -3.2466e-02,\n",
      "          1.6885e-02, -4.1460e-02,  7.6244e-02,  9.4712e-02,  3.3552e-02,\n",
      "         -7.0990e-02, -6.6892e-02,  3.9507e-02,  9.8548e-02, -5.0091e-02,\n",
      "         -4.4341e-02, -7.5934e-02,  5.2532e-02, -9.6197e-02,  5.5730e-02,\n",
      "          7.6009e-03, -6.1593e-02,  1.5084e-02,  2.8606e-02, -5.6096e-02,\n",
      "          7.4663e-02, -7.7282e-02, -7.0826e-02,  1.6305e-02,  9.4504e-02,\n",
      "          9.2170e-02, -8.2987e-02, -5.5738e-02,  4.3604e-02, -4.4809e-03,\n",
      "          4.2991e-02,  3.2845e-02,  6.1176e-02,  1.4958e-02,  5.8976e-02,\n",
      "          5.5135e-02, -1.6317e-02,  8.9101e-02,  5.9713e-02,  1.5283e-02,\n",
      "          9.0452e-02,  9.6791e-02,  6.8698e-02,  1.4545e-02, -3.8937e-02,\n",
      "          6.3490e-02,  2.6663e-02, -4.5863e-02,  3.7875e-02, -9.0706e-02,\n",
      "          7.5884e-02,  6.4169e-02,  8.6824e-02, -5.0666e-02, -3.6890e-02,\n",
      "          9.9216e-02,  3.0762e-02, -6.2772e-03, -2.6882e-02, -8.8877e-02]])), ('output.bias', tensor([-0.1623, -0.7062,  0.1708,  0.3090,  0.1257,  0.1218,  0.1092, -0.0323,\n",
      "        -0.0722, -0.3215]))])}\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('checkpoint.pth')\n",
    "print(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = fc_model.Network(checkpoint['input_size'],\n",
    "                             checkpoint['output_size'],\n",
    "                             checkpoint['hidden_layers'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=True)\n",
      "    (1): Linear(in_features=400, out_features=200, bias=True)\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = load_checkpoint('checkpoint.pth')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
